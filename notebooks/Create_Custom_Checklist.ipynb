{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating and Managing Responsible AI Checklists Using `rai-checklist-cli`\n",
    "\n",
    "This notebook demonstrates how to use the `rai-checklist-cli` library to generate and manage responsible AI checklists for machine learning projects.\n",
    "We will cover:\n",
    "\n",
    "- Listing available templates\n",
    "- Focusing on specific sections\n",
    "- Generating checklists in various formats (Markdown, YAML, JSON)\n",
    "- Creating and saving custom templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install the `rai-checklist-cli` Library\n",
    "\n",
    "Before using the `rai-checklist-cli` tool, ensure it is installed in your environment. You can install it directly from PyPI.\n",
    "\n",
    "If you're using Google Colab or another notebook environment, run the following command to install the library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rai_checklist_cli in c:\\code\\rai-checklist-cli\\venv\\lib\\site-packages (0.5.13)\n",
      "Requirement already satisfied: pyyaml in c:\\code\\rai-checklist-cli\\venv\\lib\\site-packages (from rai_checklist_cli) (6.0)\n",
      "Requirement already satisfied: tqdm in c:\\code\\rai-checklist-cli\\venv\\lib\\site-packages (from rai_checklist_cli) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\code\\rai-checklist-cli\\venv\\lib\\site-packages (from tqdm->rai_checklist_cli) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade rai_checklist_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: rai-checklist-cli\n",
      "Version: 0.5.13\n",
      "Summary: A CLI tool to generate responsible AI checklists for machine learning projects.\n",
      "Home-page: https://github.com/ByteanAtomResearch/rai-checklist-cli\n",
      "Author: Noble Ackerson\n",
      "Author-email: noblel@byteanatom.com\n",
      "License: UNKNOWN\n",
      "Location: C:\\code\\rai-checklist-cli\\venv\\Lib\\site-packages\n",
      "Requires: pyyaml, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show rai_checklist_cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries\n",
    "\n",
    "Once installed, we import the necessary modules from the `rai-checklist-cli` package and ensure that templates are accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rai_checklist_cli.checklist_generator import generate_checklist\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Understanding the Checklist Template\n",
    "\n",
    "This section shows how to list all available templates and sections defined in `templates.yaml`. We’ll use the `TemplateManager` to load and display the available templates.\n",
    "\n",
    "Explanation of Checklist Sections: Brief overview of the default sections in the provided `templates.yaml`. \n",
    "\n",
    "Example sections could include:\n",
    "\n",
    "- Deployment Monitoring\n",
    "- Ethical Considerations\n",
    "- Bias Mitigation\n",
    "- Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Templates:\n",
      "\n",
      "- customer_service_ai\n",
      "  Sections:\n",
      "\n",
      "- default\n",
      "  Sections:\n",
      "\n",
      "- education_ai\n",
      "  Sections:\n",
      "\n",
      "- financial_ai\n",
      "  Sections:\n",
      "\n",
      "- healthcare_ai\n",
      "  Sections:\n"
     ]
    }
   ],
   "source": [
    "def display_templates_and_sections():\n",
    "    # Initialize TemplateManager with default templates\n",
    "    template_manager = TemplateManager()\n",
    "\n",
    "    # Get all available templates\n",
    "    available_templates = template_manager.get_available_templates()\n",
    "\n",
    "    print(\"Available Templates:\")\n",
    "    for template_name in available_templates:\n",
    "        print(f\"\\n- {template_name}\")\n",
    "        \n",
    "        # Get the template data\n",
    "        template_data = template_manager.get_template(template_name)\n",
    "        \n",
    "        # Display sections for the template\n",
    "        print(\"  Sections:\")\n",
    "        for section in template_data.get('sections', []):\n",
    "            print(f\"    - {section['name']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    display_templates_and_sections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Focus on a Specific Section\n",
    "\n",
    "Sometimes you may want to focus on just one part of a checklist. Here’s how you can isolate a specific section of a template.\n",
    "\n",
    "**Use Case:** Demonstrate generating a checklist for an NLP project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template structure:\n",
      "==================\n",
      "\n",
      "Customer Service AI Deployment and Monitoring:\n",
      "---------------------------------------------\n",
      "- How will you monitor the chatbot's performance and customer satisfaction?\n",
      "- What is your plan for updating the chatbot as customer needs evolve?\n",
      "\n",
      "Customer Service AI Ethical Considerations:\n",
      "------------------------------------------\n",
      "- How will you ensure the chatbot respects customer privacy and data protection laws?\n",
      "- What measures are in place to prevent the chatbot from providing incorrect or harmful information?\n",
      "\n",
      "Customer Service AI Problem Definition:\n",
      "--------------------------------------\n",
      "- What customer queries or tasks will the LLM-based chatbot be responsible for?\n",
      "- How will you measure the chatbot's success in handling customer interactions?\n",
      "- What datasets (e.g., past customer queries) will be used to train the chatbot?\n",
      "\n",
      "Customer Service Chatbot Project Motivation:\n",
      "-------------------------------------------\n",
      "- What customer service problem are you aiming to solve with an LLM?\n",
      "- How will this chatbot enhance the customer experience?\n",
      "- Why is an LLM-based chatbot more efficient than traditional customer service methods?\n",
      "\n",
      "Available sections:\n",
      "===================\n",
      "['deployment_monitoring',\n",
      " 'ethical_considerations',\n",
      " 'problem_definition',\n",
      " 'project_motivation']\n",
      "\n",
      "Valid sections found: ['deployment_monitoring', 'ethical_considerations']\n",
      "Error generating checklist: KeyError - 'name'\n",
      "The generate_checklist function might need to be updated to handle the current template structure.\n"
     ]
    }
   ],
   "source": [
    "from rai_checklist_cli.template_manager import TemplateManager\n",
    "from rai_checklist_cli.checklist_generator import generate_checklist\n",
    "from pprint import pprint\n",
    "\n",
    "# Initialize TemplateManager to load default templates\n",
    "template_manager = TemplateManager()\n",
    "\n",
    "# Select the desired template\n",
    "template_name = 'customer_service_ai'\n",
    "template = template_manager.get_template(template_name)\n",
    "\n",
    "# Inspect the template structure\n",
    "print(\"Template structure:\")\n",
    "print(\"==================\")\n",
    "for section_name, section_data in template.items():\n",
    "    print(f\"\\n{section_data['title']}:\")\n",
    "    print(\"-\" * len(section_data['title']))\n",
    "    for item in section_data['items']:\n",
    "        print(f\"- {item}\")\n",
    "\n",
    "# Define the sections you want to focus on\n",
    "sections = ['deployment_monitoring', 'ethical_considerations']\n",
    "\n",
    "# Check if the sections exist in the template\n",
    "available_sections = list(template.keys())\n",
    "valid_sections = [section for section in sections if section in available_sections]\n",
    "\n",
    "print(\"\\nAvailable sections:\")\n",
    "print(\"===================\")\n",
    "pprint(available_sections)\n",
    "\n",
    "if not valid_sections:\n",
    "    print(f\"\\nWarning: None of the specified sections {sections} were found in the template.\")\n",
    "else:\n",
    "    print(f\"\\nValid sections found: {valid_sections}\")\n",
    "    # Generate the checklist\n",
    "    try:\n",
    "        checklist = generate_checklist(template, valid_sections, 'md')\n",
    "        print(f\"\\nChecklist for {template_name} (focusing on {', '.join(valid_sections)}):\")\n",
    "        print(\"=\" * 50)\n",
    "        print(checklist)\n",
    "    except KeyError as e:\n",
    "        print(f\"Error generating checklist: KeyError - {e}\")\n",
    "        print(\"The generate_checklist function might need to be updated to handle the current template structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use Case #3:** Customizing the Checklist for a Generative AI Project (multi-format)\n",
    "\n",
    "Example of how to add custom questions for specific use cases, such as generative AI bias, hallucination issues, or prompt optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YAML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified template (YAML formatted):\n",
      "deployment_monitoring:\n",
      "  items:\n",
      "  - How will you monitor the chatbot's performance and customer satisfaction?\n",
      "  - What is your plan for updating the chatbot as customer needs evolve?\n",
      "  title: Customer Service AI Deployment and Monitoring\n",
      "ethical_considerations:\n",
      "  items:\n",
      "  - How will you ensure the chatbot respects customer privacy and data protection\n",
      "    laws?\n",
      "  - What measures are in place to prevent the chatbot from providing incorrect or\n",
      "    harmful information?\n",
      "  title: Customer Service AI Ethical Considerations\n",
      "problem_definition:\n",
      "  items:\n",
      "  - What customer queries or tasks will the LLM-based chatbot be responsible for?\n",
      "  - How will you measure the chatbot's success in handling customer interactions?\n",
      "  - What datasets (e.g., past customer queries) will be used to train the chatbot?\n",
      "  title: Customer Service AI Problem Definition\n",
      "project_motivation:\n",
      "  items:\n",
      "  - What customer service problem are you aiming to solve with an LLM?\n",
      "  - How will this chatbot enhance the customer experience?\n",
      "  - Why is an LLM-based chatbot more efficient than traditional customer service methods?\n",
      "  title: Customer Service Chatbot Project Motivation\n",
      "generative_ai:\n",
      "  title: Generative AI Specific Considerations\n",
      "  items:\n",
      "  - How will you ensure that the generated content is free from harmful bias?\n",
      "  - What steps are taken to reduce hallucination in responses?\n",
      "  - How will you measure the factual accuracy of generated outputs?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TemplateManager and get the template \n",
    "template_manager = TemplateManager()\n",
    "template_name = 'customer_service_ai'\n",
    "template = template_manager.get_template(template_name)\n",
    "\n",
    "# Add the new section\n",
    "generative_ai_section = {\n",
    "    \"title\": \"Generative AI Specific Considerations\",\n",
    "    \"items\": [\n",
    "        \"How will you ensure that the generated content is free from harmful bias?\",\n",
    "        \"What steps are taken to reduce hallucination in responses?\",\n",
    "        \"How will you measure the factual accuracy of generated outputs?\"\n",
    "    ]\n",
    "}\n",
    "template['generative_ai'] = generative_ai_section\n",
    "\n",
    "# Print the template in YAML format\n",
    "print(\"Modified template (YAML formatted):\")\n",
    "print(yaml.dump(template, sort_keys=False, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified template (JSON formatted):\n",
      "{\n",
      "    \"deployment_monitoring\": {\n",
      "        \"items\": [\n",
      "            \"How will you monitor the chatbot's performance and customer satisfaction?\",\n",
      "            \"What is your plan for updating the chatbot as customer needs evolve?\"\n",
      "        ],\n",
      "        \"title\": \"Customer Service AI Deployment and Monitoring\"\n",
      "    },\n",
      "    \"ethical_considerations\": {\n",
      "        \"items\": [\n",
      "            \"How will you ensure the chatbot respects customer privacy and data protection laws?\",\n",
      "            \"What measures are in place to prevent the chatbot from providing incorrect or harmful information?\"\n",
      "        ],\n",
      "        \"title\": \"Customer Service AI Ethical Considerations\"\n",
      "    },\n",
      "    \"problem_definition\": {\n",
      "        \"items\": [\n",
      "            \"What customer queries or tasks will the LLM-based chatbot be responsible for?\",\n",
      "            \"How will you measure the chatbot's success in handling customer interactions?\",\n",
      "            \"What datasets (e.g., past customer queries) will be used to train the chatbot?\"\n",
      "        ],\n",
      "        \"title\": \"Customer Service AI Problem Definition\"\n",
      "    },\n",
      "    \"project_motivation\": {\n",
      "        \"items\": [\n",
      "            \"What customer service problem are you aiming to solve with an LLM?\",\n",
      "            \"How will this chatbot enhance the customer experience?\",\n",
      "            \"Why is an LLM-based chatbot more efficient than traditional customer service methods?\"\n",
      "        ],\n",
      "        \"title\": \"Customer Service Chatbot Project Motivation\"\n",
      "    },\n",
      "    \"generative_ai\": {\n",
      "        \"title\": \"Generative AI Specific Considerations\",\n",
      "        \"items\": [\n",
      "            \"How will you ensure that the generated content is free from harmful bias?\",\n",
      "            \"What steps are taken to reduce hallucination in responses?\",\n",
      "            \"How will you measure the factual accuracy of generated outputs?\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Initialize TemplateManager and get the template \n",
    "template_manager = TemplateManager()\n",
    "template_name = 'customer_service_ai'\n",
    "template = template_manager.get_template(template_name)\n",
    "\n",
    "# Add the new section\n",
    "generative_ai_section = {\n",
    "    \"title\": \"Generative AI Specific Considerations\",\n",
    "    \"items\": [\n",
    "        \"How will you ensure that the generated content is free from harmful bias?\",\n",
    "        \"What steps are taken to reduce hallucination in responses?\",\n",
    "        \"How will you measure the factual accuracy of generated outputs?\"\n",
    "    ]\n",
    "}\n",
    "template['generative_ai'] = generative_ai_section\n",
    "\n",
    "# Print the template in JSON format\n",
    "print(\"Modified template (JSON formatted):\")\n",
    "print(json.dumps(template, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MARKDOWN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified template (Markdown formatted):\n",
      "## Customer Service AI Deployment and Monitoring\n",
      "\n",
      "- [ ] How will you monitor the chatbot's performance and customer satisfaction?\n",
      "- [ ] What is your plan for updating the chatbot as customer needs evolve?\n",
      "\n",
      "## Customer Service AI Ethical Considerations\n",
      "\n",
      "- [ ] How will you ensure the chatbot respects customer privacy and data protection laws?\n",
      "- [ ] What measures are in place to prevent the chatbot from providing incorrect or harmful information?\n",
      "\n",
      "## Customer Service AI Problem Definition\n",
      "\n",
      "- [ ] What customer queries or tasks will the LLM-based chatbot be responsible for?\n",
      "- [ ] How will you measure the chatbot's success in handling customer interactions?\n",
      "- [ ] What datasets (e.g., past customer queries) will be used to train the chatbot?\n",
      "\n",
      "## Customer Service Chatbot Project Motivation\n",
      "\n",
      "- [ ] What customer service problem are you aiming to solve with an LLM?\n",
      "- [ ] How will this chatbot enhance the customer experience?\n",
      "- [ ] Why is an LLM-based chatbot more efficient than traditional customer service methods?\n",
      "\n",
      "## Generative AI Specific Considerations\n",
      "\n",
      "- [ ] How will you ensure that the generated content is free from harmful bias?\n",
      "- [ ] What steps are taken to reduce hallucination in responses?\n",
      "- [ ] How will you measure the factual accuracy of generated outputs?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rai_checklist_cli.template_manager import TemplateManager\n",
    "from rai_checklist_cli.checklist_generator import generate_checklist\n",
    "\n",
    "# Function to format the template into a Markdown string\n",
    "def format_template_to_markdown(template):\n",
    "    markdown_output = \"\"\n",
    "    \n",
    "    # Iterate through each section in the template and format as markdown\n",
    "    for section_name, section_content in template.items():\n",
    "        # Add the section title as a level 2 header\n",
    "        markdown_output += f\"## {section_content['title']}\\n\\n\"\n",
    "        \n",
    "        # Add the items as a list of checkboxes\n",
    "        for item in section_content['items']:\n",
    "            markdown_output += f\"- [ ] {item}\\n\"\n",
    "        \n",
    "        markdown_output += \"\\n\"  # Add spacing between sections\n",
    "    \n",
    "    return markdown_output\n",
    "\n",
    "# Initialize TemplateManager and get the template \n",
    "template_manager = TemplateManager()\n",
    "template_name = 'customer_service_ai'\n",
    "template = template_manager.get_template(template_name)\n",
    "\n",
    "# Add the new section\n",
    "generative_ai_section = {\n",
    "    \"title\": \"Generative AI Specific Considerations\",\n",
    "    \"items\": [\n",
    "        \"How will you ensure that the generated content is free from harmful bias?\",\n",
    "        \"What steps are taken to reduce hallucination in responses?\",\n",
    "        \"How will you measure the factual accuracy of generated outputs?\"\n",
    "    ]\n",
    "}\n",
    "template['generative_ai'] = generative_ai_section\n",
    "\n",
    "# Generate the Markdown-formatted output\n",
    "markdown_output = format_template_to_markdown(template)\n",
    "\n",
    "# Print the Markdown output\n",
    "print(\"Modified template (Markdown formatted):\")\n",
    "print(markdown_output)\n",
    "\n",
    "# Optional: Write the markdown to a file\n",
    "with open('checklist.md', 'w') as f:\n",
    "    f.write(markdown_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create and Save Custom Templates\n",
    "\n",
    "In this step, we’ll demonstrate how to interactively create and save a custom template using the `JupyterTemplateManager`. This is useful when the predefined templates don’t fully meet your project’s requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e3c00e70ca4621a6ebd4e891f6eed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Template Name:', placeholder='Enter template name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a70d5472e864d8897c5856aee2d7b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Add Section', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabc493495f44cdb84f899b0ad9c973d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save Template', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rai_checklist_cli.jupyter_template_manager import JupyterTemplateManager\n",
    "\n",
    "# Initialize JupyterTemplateManager to create custom templates interactively\n",
    "jupyter_template_manager = JupyterTemplateManager()\n",
    "\n",
    "# Start the process of creating a custom template\n",
    "jupyter_template_manager.create_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Using the Checklist in AI/ML Pipelines\n",
    "\n",
    "Finally we explore how to integrate the checklist generation into an AI/ML pipeline (e.g., as part of a CI/CD pipeline for model deployment) or notebook workflow to ensure every model follows responsible AI principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated how to:\n",
    "\n",
    "- List available templates and sections using `rai-checklist-cli`\n",
    "- Focus on specific sections within a template\n",
    "- Generate responsible AI checklists in multiple formats\n",
    "- Create and save custom templates interactively\n",
    "- Validate checklists against predefined rules\n",
    "\n",
    "This notebook showcases how the `rai-checklist-cli` tool can streamline responsible AI practices for machine learning projects. \n",
    "\n",
    "For more information, visit the [project’s GitHub repository](https://github.com/ByteanAtomResearch/rai-checklist-cli).\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Give it a go, extend these default templates to cover new use cases or automating the validation of responsible AI practices in future models. Or please contribute to this project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
